{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ef94ede426c5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ef94ede426c5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    NLP Practical 3\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "NLP Practical 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "    \n",
    "input_text = doc.xpath('//content/text()')\n",
    "input_label = doc.xpath('//head/keywords/text()')\n",
    "\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "talk_sentences = []\n",
    "talknum = len(input_text)\n",
    "\n",
    "for i in range(talknum):\n",
    "    temp = re.sub(r'\\([^)]*\\)', '', input_text[i])\n",
    "    temp = re.sub(r'\\n', '', input_text[i])\n",
    "    temp = temp.split('.')\n",
    "    talk_sentences.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation\n"
     ]
    }
   ],
   "source": [
    "print(talk_sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "talk_sentences_token = []\n",
    "\n",
    "for talk in talk_sentences:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent.lower()).split()\n",
    "        temp.append(tokens)#\n",
    "    talk_sentences_token.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'me',\n",
       " 'the',\n",
       " 'real',\n",
       " 'real',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'quality',\n",
       " 'growth',\n",
       " 'is',\n",
       " 'figuring',\n",
       " 'out',\n",
       " 'the',\n",
       " 'balance',\n",
       " 'between',\n",
       " 'two',\n",
       " 'activities',\n",
       " 'exploration',\n",
       " 'and',\n",
       " 'exploitation']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk_sentences_token[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_label_prepro = []\n",
    "\n",
    "for i in range(len(input_label)):\n",
    "    temp = re.sub(r' ', '', input_label[i])\n",
    "    input_label_prepro.append(temp.split(','))\n",
    "    \n",
    "#print(input_label_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['talks', 'Senses', 'augmentedreality', 'brain', 'computers', 'creativity', 'cyborg', 'demo', 'design', 'engineering', 'entrepreneur', 'innovation', 'interfacedesign', 'invention', 'neuroscience', 'potential', 'prediction', 'productdesign', 'technology', 'visualizations']\n",
      "[array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  1.]), array([ 1.,  0.,  1.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 1.,  0.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for i in range(len(input_label_prepro)):\n",
    "    temp = np.zeros(3)\n",
    "    if 'technology' in '~'.join(input_label_prepro[i]):\n",
    "        temp[0] = 1\n",
    "    if 'entertainment' in '~'.join(input_label_prepro[i]):\n",
    "        temp[1] = 1\n",
    "    if 'design' in '~'.join(input_label_prepro[i]):\n",
    "        temp[2] = 1\n",
    "    labels.append(temp)\n",
    "        \n",
    "print(input_label_prepro[9])\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels_onehot = np.zeros(len(input_label_prepro), 8)\n",
    "# for i in range(len(input_label_prepro)):\n",
    "#     labels_onehot[i][labels[i][0]*4+labels[i][1]*2+labels[i][2]*1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scratch/ms16lg2/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "labels_onehot = []\n",
    "for i in range(len(input_label_prepro)):\n",
    "    temp = np.zeros(8)\n",
    "    temp[labels[i][0]*4+labels[i][1]*2+labels[i][2]*1] = 1\n",
    "    labels_onehot.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_onehot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = talk_sentences_token[:1585]\n",
    "validation_data = talk_sentences_token[1585:1835]\n",
    "test_data = talk_sentences_token[1835:]\n",
    "\n",
    "train_labels = labels[:1585]\n",
    "validation_labels = labels[1585:1835]\n",
    "test_labels = labels[1835:]\n",
    "\n",
    "train_labels_onehot = labels_onehot[:1585]\n",
    "validation_labels_onehot = labels_onehot[1585:1835]\n",
    "test_labels_onehot = labels_onehot[1835:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085,)\n",
      "(2085, 3)\n",
      "(2085, 8)\n",
      "(1585,)\n",
      "(1585, 3)\n",
      "(1585, 8)\n",
      "(250,)\n",
      "(250, 3)\n",
      "(250, 8)\n",
      "(250,)\n",
      "(250, 3)\n",
      "(250, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(talk_sentences_token))\n",
    "print(np.shape(labels))\n",
    "print(np.shape(labels_onehot))\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(train_labels_onehot))\n",
    "print(np.shape(validation_data))\n",
    "print(np.shape(validation_labels))\n",
    "print(np.shape(validation_labels_onehot))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(test_labels))\n",
    "print(np.shape(test_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61135647  0.07066246  0.06246057  0.00630915  0.17350158  0.05362776\n",
      "  0.01198738  0.01009464]\n",
      "[ 0.292  0.108  0.164  0.024  0.224  0.112  0.032  0.044]\n",
      "[ 0.344  0.1    0.132  0.032  0.2    0.128  0.036  0.028]\n"
     ]
    }
   ],
   "source": [
    "check = np.asarray(train_labels_onehot)\n",
    "print(check.sum(0) / check.sum())\n",
    "check = np.asarray(test_labels_onehot)\n",
    "print(check.sum(0) / check.sum())\n",
    "check = np.asarray(validation_labels_onehot)\n",
    "print(check.sum(0) / check.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183771\n"
     ]
    }
   ],
   "source": [
    "train_sent = []\n",
    "\n",
    "for i in range(1585):\n",
    "    for sent in train_data[i]:\n",
    "        train_sent.append(sent)\n",
    "    \n",
    "print(np.size(train_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ted = Word2Vec(train_sent, min_count=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello' in model_ted.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_bow = []\n",
    "\n",
    "for talk in train_data:\n",
    "    N = 0\n",
    "    res = np.zeros(100)\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            if word in model_ted.vocab.keys():\n",
    "                res += model_ted[word]\n",
    "                N += 1\n",
    "    res = res / N\n",
    "    train_bow.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.40911715e-01,  -1.56305378e-01,   4.86207991e-02,\n",
       "        -1.31064025e-01,   5.26537763e-02,  -2.32653266e-01,\n",
       "        -3.71403901e-01,   1.98181616e-01,  -1.09710596e-01,\n",
       "        -3.91428094e-02,   1.62313229e-01,   6.13901740e-01,\n",
       "        -8.09069324e-01,  -4.92731090e-01,  -3.10690476e-02,\n",
       "        -4.31658135e-02,   7.90516395e-02,  -5.26039568e-01,\n",
       "         9.66794779e-02,   4.77136136e-01,  -2.40210482e-01,\n",
       "        -4.66903560e-01,   2.48389070e-01,   8.75109161e-01,\n",
       "        -6.36745903e-01,   1.84180628e-01,   6.16071252e-02,\n",
       "        -3.25912640e-01,  -1.70389712e-01,  -8.59234567e-01,\n",
       "         2.05942637e-01,   1.62702980e-01,  -1.18115005e-01,\n",
       "        -1.36019821e-01,  -2.66804856e-01,  -3.41546796e-01,\n",
       "         3.25170085e-01,   1.78417696e-02,   7.90363193e-01,\n",
       "        -3.88931256e-01,   6.01414446e-01,   2.59063676e-01,\n",
       "        -3.10316073e-01,   2.04395620e-01,   3.26113053e-01,\n",
       "         1.59183598e-01,   1.82482911e-01,  -4.61775000e-01,\n",
       "         3.55113036e-01,   2.74949415e-01,   6.07500235e-02,\n",
       "         1.83121203e-01,   2.06098967e-01,   4.73304595e-01,\n",
       "         2.71348240e-01,  -4.22963871e-01,  -2.06918756e-01,\n",
       "        -5.84827726e-01,  -8.20347253e-02,  -5.14676745e-01,\n",
       "        -6.78628299e-01,  -1.08024969e-01,  -2.05961065e-01,\n",
       "        -2.10785655e-02,   1.06826758e-01,   1.64650146e-01,\n",
       "         7.90040213e-01,  -4.35201116e-01,   1.51212679e-04,\n",
       "         1.60490549e-02,   3.86668313e-01,  -8.09496118e-01,\n",
       "        -8.31610200e-02,   2.21983942e-01,   6.72598155e-02,\n",
       "         1.78605970e-01,   2.50900476e-01,  -2.28817566e-01,\n",
       "        -2.27004634e-02,  -3.02007374e-01,  -2.83689762e-01,\n",
       "        -2.80976189e-01,  -5.79119598e-01,  -1.13192973e-01,\n",
       "         1.51166766e-01,  -4.13716722e-01,  -3.92474744e-01,\n",
       "        -2.55233066e-02,  -8.50977407e-01,   5.18345776e-02,\n",
       "         3.08605693e-01,  -3.50592885e-01,   2.10183751e-01,\n",
       "         4.71509171e-01,  -2.73822438e-01,  -4.09283589e-01,\n",
       "        -5.24075991e-01,  -2.10776429e-01,  -2.26302724e-01,\n",
       "         1.11277462e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_bow = []\n",
    "\n",
    "for talk in validation_data:\n",
    "    N = 0\n",
    "    res = np.zeros(100)\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            if word in model_ted.vocab.keys():\n",
    "                res += model_ted[word]\n",
    "                N += 1\n",
    "    res = res / N\n",
    "    validation_bow.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bow = []\n",
    "\n",
    "for talk in test_data:\n",
    "    N = 0\n",
    "    res = np.zeros(100)\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            if word in model_ted.vocab.keys():\n",
    "                res += model_ted[word]\n",
    "                N += 1\n",
    "    res = res / N\n",
    "    test_bow.append(res)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
