{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NLP Practical 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "    \n",
    "raw_text = doc.xpath('//content/text()')\n",
    "raw_label = doc.xpath('//head/keywords/text()')\n",
    "\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "talk_sentences = []\n",
    "talknum = len(raw_text)\n",
    "\n",
    "for i in range(talknum):\n",
    "    temp = re.sub(r'\\([^)]*\\)', '', raw_text[i])\n",
    "    temp = re.sub(r'\\n', '', raw_text[i])\n",
    "    temp = temp.split('.')\n",
    "    talk_sentences.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation\n"
     ]
    }
   ],
   "source": [
    "print(talk_sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "talk_sentence_word = []\n",
    "\n",
    "for talk in talk_sentences:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent.lower()).split()\n",
    "        temp.append(tokens)#\n",
    "    talk_sentence_word.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'me',\n",
       " 'the',\n",
       " 'real',\n",
       " 'real',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'quality',\n",
       " 'growth',\n",
       " 'is',\n",
       " 'figuring',\n",
       " 'out',\n",
       " 'the',\n",
       " 'balance',\n",
       " 'between',\n",
       " 'two',\n",
       " 'activities',\n",
       " 'exploration',\n",
       " 'and',\n",
       " 'exploitation']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk_sentence_word[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = {}\n",
    "\n",
    "for talk in talk_sentence_word:\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            if word in freq:\n",
    "                freq[word] += 1\n",
    "            else:\n",
    "                freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts_ted_top1000 = []\n",
    "words_top_ted = []\n",
    "\n",
    "for word, count in Counter(freq).most_common(1000):\n",
    "    counts_ted_top1000.append(count)\n",
    "    words_top_ted.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "talk_sentence_word_nostop = talk_sentence_word\n",
    "\n",
    "for stop in words_top_ted[:200]:\n",
    "    for talk in talk_sentence_word_nostop:\n",
    "        for sent in talk:\n",
    "            for word in sent:\n",
    "                if word == stop:\n",
    "                    sent.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['real',\n",
       " 'real',\n",
       " 'solution',\n",
       " 'quality',\n",
       " 'growth',\n",
       " 'figuring',\n",
       " 'balance',\n",
       " 'between',\n",
       " 'activities',\n",
       " 'exploration',\n",
       " 'exploitation']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk_sentence_word_nostop[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2085,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(talk_sentence_word_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_label = []\n",
    "\n",
    "for i in range(len(raw_label)):\n",
    "    temp = re.sub(r' ', '', raw_label[i])\n",
    "    input_label.append(temp.split(','))\n",
    "    \n",
    "#print(input_label_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['talks', 'Senses', 'augmentedreality', 'brain', 'computers', 'creativity', 'cyborg', 'demo', 'design', 'engineering', 'entrepreneur', 'innovation', 'interfacedesign', 'invention', 'neuroscience', 'potential', 'prediction', 'productdesign', 'technology', 'visualizations']\n",
      "[array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  1.]), array([ 1.,  0.,  1.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.]), array([ 1.,  0.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "labels_binary = []\n",
    "\n",
    "for i in range(len(input_label)):\n",
    "    temp = np.zeros(3)\n",
    "    if 'technology' in '~'.join(input_label[i]):\n",
    "        temp[0] = 1\n",
    "    if 'entertainment' in '~'.join(input_label[i]):\n",
    "        temp[1] = 1\n",
    "    if 'design' in '~'.join(input_label[i]):\n",
    "        temp[2] = 1\n",
    "    labels_binary.append(temp)\n",
    "        \n",
    "print(input_label[9])\n",
    "print(labels_binary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = list(zip(talk_sentence_word_nostop, labels_binary))\n",
    "random.shuffle(temp)\n",
    "talk_sentence_word_nostop_shuffle, labels_binary_shuffle = zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scratch/ms16lg2/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "labels_onehot = []\n",
    "for i in range(len(input_label)):\n",
    "    temp = np.zeros(8)\n",
    "    temp[labels_binary[i][0]*4+labels_binary[i][1]*2+labels_binary[i][2]*1] = 1\n",
    "    labels_onehot.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scratch/ms16lg2/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "labels_onehot_shuffle = []\n",
    "for i in range(len(input_label)):\n",
    "    temp = np.zeros(8)\n",
    "    temp[labels_binary_shuffle[i][0]*4+labels_binary_shuffle[i][1]*2+labels_binary_shuffle[i][2]*1] = 1\n",
    "    labels_onehot_shuffle.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = talk_sentence_word_nostop[:1835]\n",
    "test_data = talk_sentence_word_nostop[1835:]\n",
    "\n",
    "train_labels = labels_binary[:1835]\n",
    "test_labels = labels_binary[1835:]\n",
    "\n",
    "train_labels_onehot = labels_onehot[:1835]\n",
    "test_labels_onehot = labels_onehot[1835:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_shuffle = talk_sentence_word_nostop_shuffle[:1835]\n",
    "test_data_shuffle = talk_sentence_word_nostop_shuffle[1835:]\n",
    "\n",
    "train_labels_shuffle = labels_binary_shuffle[:1835]\n",
    "test_labels_shuffle = labels_binary_shuffle[1835:]\n",
    "\n",
    "train_labels_onehot_shuffle = labels_onehot_shuffle[:1835]\n",
    "test_labels_onehot_shuffle = labels_onehot_shuffle[1835:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085,)\n",
      "(2085, 3)\n",
      "(2085, 8)\n",
      "(1835,)\n",
      "(1835, 3)\n",
      "(1835, 8)\n",
      "(250,)\n",
      "(250, 3)\n",
      "(250, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(talk_sentence_word_nostop))\n",
    "print(np.shape(labels_binary))\n",
    "print(np.shape(labels_onehot))\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(train_labels_onehot))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(test_labels))\n",
    "print(np.shape(test_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085,)\n",
      "(2085, 3)\n",
      "(2085, 8)\n",
      "(1835,)\n",
      "(1835, 3)\n",
      "(1835, 8)\n",
      "(250,)\n",
      "(250, 3)\n",
      "(250, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(talk_sentence_word_nostop_shuffle))\n",
    "print(np.shape(labels_binary_shuffle))\n",
    "print(np.shape(labels_onehot_shuffle))\n",
    "print(np.shape(train_data_shuffle))\n",
    "print(np.shape(train_labels_shuffle))\n",
    "print(np.shape(train_labels_onehot_shuffle))\n",
    "print(np.shape(test_data_shuffle))\n",
    "print(np.shape(test_labels_shuffle))\n",
    "print(np.shape(test_labels_onehot_shuffle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57493188  0.0746594   0.0719346   0.00980926  0.17711172  0.06376022\n",
      "  0.01525886  0.01253406]\n",
      "[ 0.292  0.108  0.164  0.024  0.224  0.112  0.032  0.044]\n"
     ]
    }
   ],
   "source": [
    "check = np.asarray(train_labels_onehot)\n",
    "print(check.sum(0) / check.sum())\n",
    "check = np.asarray(test_labels_onehot)\n",
    "print(check.sum(0) / check.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53569482  0.07847411  0.08446866  0.01089918  0.18692098  0.07084469\n",
      "  0.01961853  0.01307902]\n",
      "[ 0.58   0.08   0.072  0.016  0.152  0.06   0.     0.04 ]\n"
     ]
    }
   ],
   "source": [
    "check = np.asarray(train_labels_onehot_shuffle)\n",
    "print(check.sum(0) / check.sum())\n",
    "check = np.asarray(test_labels_onehot_shuffle)\n",
    "print(check.sum(0) / check.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lenghts = []\n",
    "\n",
    "for talk in train_data:\n",
    "    N = 0\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            N += 1\n",
    "    train_lenghts.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 807, 852, 493, 971, 823, 676, 692, 977, 622]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lenghts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lenghts = []\n",
    "\n",
    "for talk in test_data:\n",
    "    N = 0\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            N += 1\n",
    "    test_lenghts.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[208, 1014, 826, 203, 1718, 241, 100, 979, 944, 1273]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lenghts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n"
     ]
    }
   ],
   "source": [
    "train_talk_word = []\n",
    "\n",
    "for talk in train_data:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            temp.append(word)\n",
    "    train_talk_word.append(temp)\n",
    "    \n",
    "print(len(train_talk_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "test_talk_word = []\n",
    "\n",
    "for talk in test_data:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            temp.append(word)\n",
    "    test_talk_word.append(temp)\n",
    "    \n",
    "print(len(test_talk_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire',\n",
       " 'nine',\n",
       " 'days',\n",
       " 'archive',\n",
       " '175',\n",
       " 'films',\n",
       " '16',\n",
       " 'millimeter',\n",
       " 'negative',\n",
       " 'books']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_talk_word[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sent = []\n",
    "\n",
    "for talk in train_data:\n",
    "    for sent in talk:\n",
    "        train_sent.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ted = Word2Vec(train_sent, min_count=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_talk_word_emb = []\n",
    "\n",
    "for talk in train_talk_word:\n",
    "    temp = []\n",
    "    for word in talk:\n",
    "        if word in model_ted.vocab.keys():\n",
    "            temp.append(model_ted[word])\n",
    "        else:\n",
    "            temp.append(np.zeros(100))\n",
    "    train_talk_word_emb.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_talk_word_emb = []\n",
    "\n",
    "for talk in test_talk_word:\n",
    "    temp = []\n",
    "    for word in talk:\n",
    "        if word in model_ted.vocab.keys():\n",
    "            temp.append(model_ted[word])\n",
    "        else:\n",
    "            temp.append(np.zeros(100))\n",
    "    test_talk_word_emb.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 807, 852, 493, 971, 823, 676, 692, 977, 622]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lenghts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_talk_word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_talk_word_emb_exp = []\n",
    "\n",
    "for i in range(len(train_talk_word_emb)):\n",
    "    temp = []\n",
    "    for j in range(max(train_lenghts)):\n",
    "        if j <= (train_lenghts[i]-1):\n",
    "            temp.append(train_talk_word_emb[i][j])\n",
    "        else:\n",
    "            temp.append(np.zeros(100))\n",
    "    train_talk_word_emb_exp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_talk_word_emb_exp = []\n",
    "\n",
    "for i in range(len(test_talk_word_emb)):\n",
    "    temp = []\n",
    "    for j in range(max(train_lenghts)):\n",
    "        if j <= (test_lenghts[i]-1):\n",
    "            temp.append(test_talk_word_emb[i][j])\n",
    "        else:\n",
    "            temp.append(np.zeros(100))\n",
    "    test_talk_word_emb_exp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(test_talk_word_emb_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.shape(train_talk_word_emb_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_nodes = 100\n",
    "hidden_nodes = 20\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# NN inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 100, 1])\n",
    "#xl = tf.placeholder(tf.float32, shape=[None])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "\n",
    "# Defining RNN\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=100, state_is_tuple=True)\n",
    "\n",
    "h_rnn, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=cell,\n",
    "    inputs=x,\n",
    "    #sequence_length=xl,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "h_bow = tf.reduce_mean(h_rnn, 0)\n",
    "\n",
    "# First normal layer\n",
    "W = weight_variable([100, hidden_nodes])\n",
    "b = bias_variable([hidden_nodes])\n",
    "h = tf.tanh(tf.matmul(h_bow, W) + b)\n",
    "\n",
    "# Output Layer\n",
    "V = weight_variable([hidden_nodes, 8])\n",
    "c = bias_variable([8])\n",
    "y = tf.nn.softmax(tf.matmul(h, V) + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll use the cross entropy loss function \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "\n",
    "# And classification accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# And the Adam optimiser\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-3b56504d5887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlabels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_labels_onehot\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/scratch/ms16lg2/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/scratch/ms16lg2/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    617\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Start a tf session and run the optimisation algorithm\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "input_data = train_talk_word_emb\n",
    "input_labels = train_labels_onehot\n",
    "epochs = 100\n",
    "bs = 10\n",
    "train_accuracy = np.zeros(epochs)\n",
    "test_accuracy = np.zeros(epochs)\n",
    "N = 0\n",
    "C = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for bat in range(len(input_data) // bs):\n",
    "        print(\"hi\")\n",
    "        data_batch = input_data[bat * bs : (bat + 1) * bs]\n",
    "        labels_batch = input_labels[bat * bs : (bat + 1) * bs]\n",
    "        train_accuracy[epoch] += sess.run(accuracy, feed_dict={x: data_batch, y_: labels_batch}) / (len(input_data) // bs)\n",
    "        test_accuracy[epoch] += sess.run(accuracy, feed_dict={x: test_bow, y_: test_labels_onehot}) / (len(input_data) // bs)\n",
    "        sess.run(train_step, feed_dict={x: data_batch, y_: labels_batch})\n",
    "    temp = list(zip(input_data, input_labels))\n",
    "    random.shuffle(temp)\n",
    "    input_data, input_labels = zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_lenghts = np.array(train_lenghts)\n",
    "train_talk_word_emb_exp = np.array(train_talk_word_emb_exp)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=100, state_is_tuple=True)\n",
    "\n",
    "outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=train_lenghts[:1],\n",
    "    inputs=train_talk_word_emb_exp[:1])\n",
    "\n",
    "result = tf.contrib.learn.run_n(\n",
    "    {\"outputs\": outputs, \"last_states\": last_states},\n",
    "    n=1,\n",
    "    feed_dict=None)\n",
    "\n",
    "#assert result[0][\"outputs\"].shape == (1, 100, 100)\n",
    "print(result[0][\"outputs\"])\n",
    "\n",
    "# Outputs for the second example past past length 6 should be 0\n",
    "#assert (result[0][\"outputs\"][1,7,:] == np.zeros(cell.output_size)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create input data\n",
    "X = np.random.randn(2, 10, 8)\n",
    "\n",
    "# The second example is of length 6 \n",
    "X[1,6:] = 0\n",
    "X_lengths = [10, 6]\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "\n",
    "outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=X_lengths,\n",
    "    inputs=X)\n",
    "\n",
    "result = tf.contrib.learn.run_n(\n",
    "    {\"outputs\": outputs, \"last_states\": last_states},\n",
    "    n=1,\n",
    "    feed_dict=None)\n",
    "\n",
    "assert result[0][\"outputs\"].shape == (2, 10, 64)\n",
    "print(result[0][\"outputs\"])\n",
    "\n",
    "# Outputs for the second example past past length 6 should be 0\n",
    "assert (result[0][\"outputs\"][1,7,:] == np.zeros(cell.output_size)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.random.randn(2, 10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
